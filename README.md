# Scraper SAT - Sistema de Recomendaciones Acad茅micas (Full Stack)

Este proyecto es una plataforma integral para agregar, procesar y visualizar recomendaciones de c谩tedras universitarias, extra铆das autom谩ticamente de grupos de Facebook mediante scraping y procesamiento de lenguaje natural (NLP).

> **Nota**: Este documento se centra principalmente en la arquitectura y funcionalidad del **Backend**.

##  Arquitectura del Backend

El backend est谩 construido con **Django 6.0** y **Django REST Framework (DRF)**. Utiliza una arquitectura modular separada en aplicaciones con responsabilidades espec铆ficas.

### Estructura de Directorios

```text
backend/
 academic/          # Gesti贸n de entidades acad茅micas (Docentes, Comisiones)
 recommendations/   # L贸gica central de recomendaciones y an谩lisis
 scraping/          # Gesti贸n de tareas de scraping y datos crudos
 users/             # Gesti贸n de usuarios y autenticaci贸n
 config/            # Configuraci贸n global del proyecto (settings, urls)
 utils/             # Utilidades transversales
```

---

##  Aplicaciones y Funcionalidad

### 1.  Academic (`backend/academic`)

Responsable de modelar la estructura est谩tica de la universidad (profesores y cursos).

* **Modelos Principales**:
  * **`Docente`**: Almacena informaci贸n de profesores. Incluye un campo `alias_search` para mejorar la b煤squeda difusa.
  * **`Comision`**: Representa una instancia de una materia (C谩tedra). Vincula un c贸digo 煤nico, un docente titular, horarios y metadatos administrativos.

* **Funcionalidad Clave**:
  * Catalogaci贸n unificada de toda la oferta acad茅mica.
  * Base sobre la cual se agregan las recomendaciones.

### 2.  Recommendations (`backend/recommendations`)

El "cerebro" del sistema. Transforma datos crudos en informaci贸n 煤til.

* **Modelos Principales**:
  * **`Recomendacion`**: El n煤cleo del valor. Vincula un `Post_Scrapeado` con una `Comision`.
    * **An谩lisis NLP**: Campos `sentimiento` (Positivo/Negativo/Neutral) y `confianza` (0-1).
    * **Extracci贸n de Datos**: `prob_aprobar`, `toma_tp`, `asistencia`.
    * **Votaci贸n**: Sistema de `votos_utilidad` para ranking comunitario.
  * **`Cache_Metadatos`**: Sistema de versionado (entero incremental) que permite a los clientes (Frontend/Extensi贸n) verificar si necesitan redescargar el dataset de recomendaciones, optimizando el ancho de banda.

### 3.  Scraping (`backend/scraping`)

Motor de ingesta de datos. Gestiona la orquestaci贸n del scraping, aunque la ejecuci贸n real puede ocurrir en clientes externos (extensi贸n de navegador o workers).

* **Modelos Principales**:
  * **`Grupos`**: URLs de fuentes de datos (Grupos de Facebook).
  * **`Tarea_Scrapeo`**: Define **qu茅** buscar. Contiene `keywords` y una frecuencia de actualizaci贸n.
  * **`Sesion_Scraping`**: Telemetr铆a y logs de cada ejecuci贸n de scraping. Registra inicio, fin, estado y cantidad de posts encontrados.
  * **`Post_Scrapeado`**: Data Lake de contenido crudo. Almacena el texto original del post y metadatos de Facebook para auditor铆a y reprocesamiento.

* **Flujo de Trabajo**:
    1. El Backend genera una `Tarea_Scrapeo`.
    2. Un Worker/Extensi贸n consulta la API por tareas pendientes.
    3. El Worker ejecuta el scraping y sube los resultados como `Post_Scrapeado`.
    4. El Backend (signal/task) procesa el post para crear `Recomendacion`.

### 4.  Users (`backend/users`)

Gesti贸n personalizada de usuarios.

* **Modelos**:
  * **`User`**: Hereda de `AbstractUser` de Django. Preparado para extensi贸n futura (perfiles, avatares, roles acad茅micos).
* **Funcionalidad**:
  * Autenticaci贸n v铆a Token/Session para la API.
  * Control de acceso para colaboradores del scraping.

---

##  API Reference

El proyecto expone una API RESTful en `/api/`.

| Endpoint | M茅todo | Descripci贸n |
|----------|--------|-------------|
| `/api/catedras/` | GET | Listado de comisiones y sus recomendaciones agregadas. |
| `/api/grupos/` | GET, POST | Gesti贸n de grupos de Facebook a monitorear. |
| `/api/tareas/` | GET, POST | Tareas de scraping pendientes para workers. |
| `/api/sesiones/` | POST | Reporte de progreso/finalizaci贸n de scraping. |
| `/api/posts/` | POST | Ingesta de nuevos posts crudos. |

---

##  Configuraci贸n y Tecnolog铆as

* **Base de Datos**: SQLite (Dev) / PostgreSQL (Prod - Recomendado).
* **Cola de Tareas**: Celery + Redis (para procesamiento as铆ncrono de NLP).
* **Servidor WSGI**: Gunicorn (Configurado en `requirements.txt`).
* **Variables de Entorno**: Gestionadas via `django-environ` (ver `.env.example`).

### Iniciar Entorno Local

```bash
# Activar entorno virtual
source venv/bin/activate

# Instalar dependencias
pip install -r backend/requirements.txt

# Migraciones
python backend/manage.py migrate

# Iniciar servidor
python backend/manage.py runserver
```
